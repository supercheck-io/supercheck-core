version: "3.8"

services:
  # Supercheck App (Next.js Frontend) - Isolated to app nodes
  supercheck-app:
    image: ghcr.io/supercheck-io/supercheck/app:1.0.5-beta
    environment:
      # External Database Configuration (Neon/PlanetScale)
      - DATABASE_URL_FILE=/run/secrets/database_url
      - DB_SSL_MODE=require
      - DB_CONNECTION_LIMIT=10
      - DB_POOL_TIMEOUT=30000

      # External Redis Configuration (Redis Cloud)
      - REDIS_URL_FILE=/run/secrets/redis_url
      - REDIS_CONNECTION_TIMEOUT=5000
      - REDIS_COMMAND_TIMEOUT=5000
      - REDIS_MAX_RETRIES=3

      # External S3 Configuration
      - AWS_REGION=us-east-1
      - AWS_ACCESS_KEY_ID_FILE=/run/secrets/aws_access_key_id
      - AWS_SECRET_ACCESS_KEY_FILE=/run/secrets/aws_secret_access_key
      - S3_JOB_BUCKET_NAME=supercheck-job-artifacts
      - S3_TEST_BUCKET_NAME=supercheck-test-artifacts
      - S3_FORCE_PATH_STYLE=false
      - S3_OPERATION_TIMEOUT=10000
      - S3_MAX_RETRIES=3

      # App Configuration
      - NODE_ENV=production
      - NEXT_PUBLIC_APP_URL=https://demo.supercheck.io
      - BETTER_AUTH_URL=https://demo.supercheck.io
      - BETTER_AUTH_SECRET_FILE=/run/secrets/auth_secret
      - RUNNING_CAPACITY=6
      - QUEUED_CAPACITY=50
      - MAX_CONCURRENT_EXECUTIONS=2 # Max parallel tests per worker (default: 1)
      - TEST_EXECUTION_TIMEOUT_MS=120000
      - JOB_EXECUTION_TIMEOUT_MS=900000

      # Security Configuration
      - CREDENTIAL_ENCRYPTION_KEY_FILE=/run/secrets/credential_encryption_key
      - VARIABLES_ENCRYPTION_KEY_FILE=/run/secrets/variables_encryption_key

      # Notification Configuration
      - NEXT_PUBLIC_MAX_JOB_NOTIFICATION_CHANNELS=10
      - NEXT_PUBLIC_MAX_MONITOR_NOTIFICATION_CHANNELS=10

      # SMTP Configuration
      - SMTP_HOST=smtp.resend.com
      - SMTP_PORT=587
      - SMTP_USER=resend
      - SMTP_PASSWORD_FILE=/run/secrets/smtp_password
      - SMTP_SECURE=false
      - SMTP_FROM_EMAIL=notifications@demo.supercheck.io

      # AI Configuration
      - AI_PROVIDER=openai
      - AI_MODEL=gpt-4o-mini
      - OPENAI_API_KEY_FILE=/run/secrets/openai_api_key
      - AI_TIMEOUT_MS=90000
      - AI_MAX_RETRIES=2
      - AI_TEMPERATURE=0.1

      # Playground Configuration
      - PLAYGROUND_CLEANUP_ENABLED=true
      - PLAYGROUND_CLEANUP_CRON=0 */12 * * *
      - PLAYGROUND_CLEANUP_MAX_AGE_HOURS=24

      # Admin Configuration
      - MAX_PROJECTS_PER_ORG=10
      - DEFAULT_PROJECT_NAME=Default Project

      # Playwright Configuration
      - PLAYWRIGHT_HEADLESS=true
      - PLAYWRIGHT_RETRIES=1
      - PLAYWRIGHT_TRACE=on
      - PLAYWRIGHT_SCREENSHOT=on
      - PLAYWRIGHT_VIDEO=on
      - ENABLE_FIREFOX=false
      - ENABLE_WEBKIT=false
      - ENABLE_MOBILE=false

    secrets:
      - database_url
      - redis_url
      - aws_access_key_id
      - aws_secret_access_key
      - auth_secret
      - credential_encryption_key
      - variables_encryption_key
      - smtp_password
      - openai_api_key
    ports:
      - "3000:3000"
    networks:
      - supercheck-network
    deploy:
      replicas: 2
      placement:
        constraints:
          - node.labels.service_type == app # Isolate to app nodes
        preferences:
          - spread: node.id
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
        monitor: 30s
      rollback_config:
        parallelism: 1
        delay: 5s
        failure_action: pause
        monitor: 30s
      resources:
        limits:
          cpus: "1.0"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "const http = require('http'); const req = http.request({hostname: 'localhost', port: 3000, path: '/', timeout: 5000}, (res) => process.exit(res.statusCode < 400 ? 0 : 1)); req.on('error', () => process.exit(1)); req.end();",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,environment"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.supercheck-app.rule=Host(`demo.supercheck.io`)"
      - "traefik.http.routers.supercheck-app.entrypoints=websecure"
      - "traefik.http.routers.supercheck-app.tls.certresolver=letsencrypt"
      - "traefik.http.services.supercheck-app.loadbalancer.server.port=3000"
      - "traefik.docker.network=supercheck-network"

  # Supercheck Worker (NestJS Test Execution) - Isolated to worker nodes
  supercheck-worker:
    image: ghcr.io/supercheck-io/supercheck/worker:1.0.5-beta
    environment:
      # Inherit all environment variables from app
      - DATABASE_URL_FILE=/run/secrets/database_url
      - DB_SSL_MODE=require
      - DB_CONNECTION_LIMIT=5
      - DB_POOL_TIMEOUT=30000

      - REDIS_URL_FILE=/run/secrets/redis_url
      - REDIS_CONNECTION_TIMEOUT=5000
      - REDIS_COMMAND_TIMEOUT=5000
      - REDIS_MAX_RETRIES=3

      - AWS_REGION=us-east-1
      - AWS_ACCESS_KEY_ID_FILE=/run/secrets/aws_access_key_id
      - AWS_SECRET_ACCESS_KEY_FILE=/run/secrets/aws_secret_access_key
      - S3_JOB_BUCKET_NAME=supercheck-job-artifacts
      - S3_TEST_BUCKET_NAME=supercheck-test-artifacts
      - S3_FORCE_PATH_STYLE=false
      - S3_OPERATION_TIMEOUT=10000
      - S3_MAX_RETRIES=3
      - S3_MULTIPART_THRESHOLD=10485760 # 10MB
      - S3_MULTIPART_CHUNKSIZE=5242880 # 5MB

      # Worker-specific configuration
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=1024 --expose-gc --experimental-worker
      - UV_THREADPOOL_SIZE=4
      - RUNNING_CAPACITY=6
      - QUEUED_CAPACITY=50
      - MAX_CONCURRENT_EXECUTIONS=2 # Max parallel tests per worker (default: 1)
      - TEST_EXECUTION_TIMEOUT_MS=120000
      - JOB_EXECUTION_TIMEOUT_MS=900000

      # Playwright Configuration
      - PLAYWRIGHT_HEADLESS=true
      - PLAYWRIGHT_RETRIES=1
      - PLAYWRIGHT_TRACE=on
      - PLAYWRIGHT_SCREENSHOT=on
      - PLAYWRIGHT_VIDEO=on
      - ENABLE_FIREFOX=false
      - ENABLE_WEBKIT=false
      - ENABLE_MOBILE=false
    secrets:
      - database_url
      - redis_url
      - aws_access_key_id
      - aws_secret_access_key
    networks:
      - supercheck-network
    deploy:
      replicas: 4
      placement:
        constraints:
          - node.labels.service_type == worker # Isolate to worker nodes
        preferences:
          - spread: node.id
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 2
        delay: 10s
        failure_action: rollback
        monitor: 30s
      rollback_config:
        parallelism: 1
        delay: 5s
        failure_action: pause
        monitor: 30s
      resources:
        limits:
          cpus: "1.5"
          memory: 2G
        reservations:
          cpus: "0.5"
          memory: 1G
    healthcheck:
      test:
        [
          "CMD",
          "node",
          "-e",
          "const http = require('http'); const req = http.request({hostname: 'localhost', port: 3001, path: '/health', timeout: 5000}, (res) => process.exit(res.statusCode === 200 ? 0 : 1)); req.on('error', () => process.exit(1)); req.end();",
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
        labels: "service,environment"
    volumes:
      - /tmp:/tmp # Shared tmp for Playwright

  # Traefik Reverse Proxy - Runs on manager nodes
  traefik:
    image: traefik:v3.0
    command:
      # Enable Docker Swarm provider
      - --providers.swarm.endpoint=unix:///var/run/docker.sock
      - --providers.swarm.exposedByDefault=false
      - --providers.swarm.network=supercheck-network

      # Entry points
      - --entrypoints.web.address=:80
      - --entrypoints.websecure.address=:443
      - --entrypoints.web.http.redirections.entrypoint.to=websecure
      - --entrypoints.web.http.redirections.entrypoint.scheme=https

      # Let's Encrypt configuration
      - --certificatesresolvers.letsencrypt.acme.httpchallenge=true
      - --certificatesresolvers.letsencrypt.acme.httpchallenge.entrypoint=web
      - --certificatesresolvers.letsencrypt.acme.email=admin@yourdomain.com
      - --certificatesresolvers.letsencrypt.acme.storage=/letsencrypt/acme.json

      # API and Dashboard
      - --api.dashboard=true
      - --api.insecure=false

      # Metrics
      - --metrics.prometheus=true
      - --metrics.prometheus.addEntryPointsLabels=true
      - --metrics.prometheus.addServicesLabels=true

      # Logging
      - --log.level=INFO
      - --accesslog=true
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080" # Dashboard
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - traefik-letsencrypt:/letsencrypt
    networks:
      - supercheck-network
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.1"
          memory: 128M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.traefik.rule=Host(`traefik.demo.supercheck.io`)"
        - "traefik.http.routers.traefik.entrypoints=websecure"
        - "traefik.http.routers.traefik.tls.certresolver=letsencrypt"
        - "traefik.http.routers.traefik.service=api@internal"
        - "traefik.http.services.traefik.loadbalancer.server.port=8080"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Prometheus Monitoring - Runs on manager nodes
  prometheus:
    image: prom/prometheus:latest
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--web.console.libraries=/etc/prometheus/console_libraries"
      - "--web.console.templates=/etc/prometheus/consoles"
      - "--storage.tsdb.retention.time=200h"
      - "--web.enable-lifecycle"
      - "--web.enable-admin-api"
    volumes:
      - prometheus_data:/prometheus
      - prometheus_config:/etc/prometheus
    networks:
      - supercheck-network
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "0.5"
          memory: 512M
        reservations:
          cpus: "0.2"
          memory: 256M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.prometheus.rule=Host(`prometheus.demo.supercheck.io`)"
        - "traefik.http.routers.prometheus.entrypoints=websecure"
        - "traefik.http.routers.prometheus.tls.certresolver=letsencrypt"
        - "traefik.http.services.prometheus.loadbalancer.server.port=9090"
        - "traefik.docker.network=supercheck-network"

  # Grafana Dashboard - Runs on manager nodes
  grafana:
    image: grafana/grafana:latest
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123 # Change in production
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    volumes:
      - grafana_data:/var/lib/grafana
      - grafana_provisioning:/etc/grafana/provisioning
    networks:
      - supercheck-network
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "0.3"
          memory: 256M
        reservations:
          cpus: "0.1"
          memory: 128M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.grafana.rule=Host(`grafana.demo.supercheck.io`)"
        - "traefik.http.routers.grafana.entrypoints=websecure"
        - "traefik.http.routers.grafana.tls.certresolver=letsencrypt"
        - "traefik.http.services.grafana.loadbalancer.server.port=3000"
        - "traefik.docker.network=supercheck-network"

  # Node Exporter for host metrics - Global deployment
  node-exporter:
    image: prom/node-exporter:latest
    command:
      - "--path.procfs=/host/proc"
      - "--path.rootfs=/rootfs"
      - "--path.sysfs=/host/sys"
      - "--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)"
    volumes:
      - "/proc:/host/proc:ro"
      - "/sys:/host/sys:ro"
      - "/:/rootfs:ro"
    networks:
      - supercheck-network
    deploy:
      mode: global # Deploy on every node
      resources:
        limits:
          cpus: "0.1"
          memory: 64M
        reservations:
          cpus: "0.05"
          memory: 32M

  # cAdvisor for container metrics - Global deployment
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    networks:
      - supercheck-network
    deploy:
      mode: global # Deploy on every node
      resources:
        limits:
          cpus: "0.2"
          memory: 128M
        reservations:
          cpus: "0.1"
          memory: 64M

  # AlertManager for alerts - Runs on manager nodes
  alertmanager:
    image: prom/alertmanager:latest
    command:
      - "--config.file=/etc/alertmanager/config.yml"
      - "--storage.path=/alertmanager"
      - "--web.external-url=http://alertmanager.demo.supercheck.io"
    volumes:
      - alertmanager_data:/alertmanager
      - alertmanager_config:/etc/alertmanager
    networks:
      - supercheck-network
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      resources:
        limits:
          cpus: "0.2"
          memory: 128M
        reservations:
          cpus: "0.1"
          memory: 64M
      labels:
        - "traefik.enable=true"
        - "traefik.http.routers.alertmanager.rule=Host(`alertmanager.demo.supercheck.io`)"
        - "traefik.http.routers.alertmanager.entrypoints=websecure"
        - "traefik.http.routers.alertmanager.tls.certresolver=letsencrypt"
        - "traefik.http.services.alertmanager.loadbalancer.server.port=9093"
        - "traefik.docker.network=supercheck-network"

# Docker Secrets for sensitive data
secrets:
  database_url:
    external: true
  redis_url:
    external: true
  aws_access_key_id:
    external: true
  aws_secret_access_key:
    external: true
  auth_secret:
    external: true
  credential_encryption_key:
    external: true
  variables_encryption_key:
    external: true
  smtp_password:
    external: true
  openai_api_key:
    external: true

# Docker Networks
networks:
  supercheck-network:
    driver: overlay
    attachable: true
    encrypted: true
    ipam:
      config:
        - subnet: 10.0.9.0/24

# Docker Volumes
volumes:
  traefik-letsencrypt:
    driver: local
  prometheus_data:
    driver: local
  prometheus_config:
    driver: local
  grafana_data:
    driver: local
  grafana_provisioning:
    driver: local
  alertmanager_data:
    driver: local
  alertmanager_config:
    driver: local
